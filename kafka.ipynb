{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "343d6851",
   "metadata": {},
   "source": [
    "# Producer Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e85482df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from kafka import KafkaProducer\n",
    "import csv\n",
    "\n",
    "kafka_url = 'kafka:9092'\n",
    "\n",
    "#Démarrer le producteur Kafka\n",
    "producer = KafkaProducer(bootstrap_servers=kafka_url, value_serializer=lambda v: str(v).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da4f7c0",
   "metadata": {},
   "source": [
    "## Envoi de message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d737654a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Envoyé:Message 0\n",
      "Envoyé:Message 1\n",
      "Envoyé:Message 2\n",
      "Envoyé:Message 3\n",
      "Envoyé:Message 4\n",
      "Envoyé:Message 5\n",
      "Envoyé:Message 6\n",
      "Envoyé:Message 7\n",
      "Envoyé:Message 8\n",
      "Envoyé:Message 9\n"
     ]
    }
   ],
   "source": [
    "topic = 'topic-example'\n",
    "\n",
    "for i in range(10):\n",
    "    message = f'Message {i}'\n",
    "    producer.send(topic, value=message)\n",
    "    print(f'Envoyé:{message}')\n",
    "    time.sleep(1) # Pause pour simuler un flux\n",
    "    \n",
    "producer.flush()\n",
    "producer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1733f7",
   "metadata": {},
   "source": [
    "## Consumer Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83bea950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liste des messages reçus:\n",
      "Reçu: Message 0\n",
      "Reçu: Message 1\n",
      "Reçu: Message 2\n",
      "Reçu: Message 3\n",
      "Reçu: Message 4\n",
      "Reçu: Message 5\n",
      "Reçu: Message 6\n",
      "Reçu: Message 7\n",
      "Reçu: Message 8\n",
      "Reçu: Message 9\n"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaConsumer\n",
    "\n",
    "consumer = KafkaConsumer(\n",
    "    topic,\n",
    "    bootstrap_servers=[kafka_url],\n",
    "    auto_offset_reset ='earliest',\n",
    "    consumer_timeout_ms=1000,\n",
    "    value_deserializer=lambda value: value.decode('utf-8'),\n",
    "    \n",
    ")\n",
    "\n",
    "print(\"Liste des messages reçus:\")\n",
    "for message in consumer:\n",
    "    print(f'Reçu: {message.value}')\n",
    "    \n",
    "consumer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75268f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read the CSV file\n",
    "with open('data/test.csv', mode='r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    header = next(reader)  # skip header if needed\n",
    "\n",
    "    for row in reader:\n",
    "        message = ','.join(row)  # convert row to string\n",
    "        producer.send(topic, value=message)\n",
    "        print(f'Envoyé: {message}')\n",
    "        time.sleep(1)  # simulate streaming\n",
    "\n",
    "producer.flush()\n",
    "producer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05779d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_url = 'kafka:9092'\n",
    "\n",
    "# Démarrer le producteur Kafka\n",
    "producer = KafkaProducer(bootstrap_servers=kafka_url, value_serializer=lambda v: str(v).encode('utf-8'))\n",
    "topic2 = 'topic-example-file'\n",
    "\n",
    "# Open and read the CSV file\n",
    "with open('data/film.csv','r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    header = next(reader)  # skip header if needed\n",
    "\n",
    "    for i, row in enumerate(reader):\n",
    "        if i >= 25:  # limit to first 100 rows\n",
    "            break\n",
    "        message = ','.join(row)  # convert row to string\n",
    "        producer.send(topic2, value=message)\n",
    "        print(f'Envoyé: {message}')\n",
    "        time.sleep(1)  # simulate streaming\n",
    "\n",
    "producer.flush()\n",
    "producer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa207232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liste des messages reçus:\n",
      "Reçu: 1,ACADEMY DINOSAUR,An Epic Drama of a Feminist And a Mad Scientist who must Battle a Teacher in The Canadian Rockies,2006,1,,6,0.99,86,20.99,PG,Deleted Scenes,Behind the Scenes,2006-02-15 05:03:42\n",
      "Reçu: 2,ACE GOLDFINGER,A Astounding Epistle of a Database Administrator And a Explorer who must Find a Car in Ancient China,2006,1,,3,4.99,48,12.99,G,Trailers,Deleted Scenes,2006-02-15 05:03:42\n",
      "Reçu: 3,ADAPTATION HOLES,A Astounding Reflection of a Lumberjack And a Car who must Sink a Lumberjack in A Baloon Factory,2006,1,,7,2.99,50,18.99,NC-17,Trailers,Deleted Scenes,2006-02-15 05:03:42\n",
      "Reçu: 4,AFFAIR PREJUDICE,A Fanciful Documentary of a Frisbee And a Lumberjack who must Chase a Monkey in A Shark Tank,2006,1,,5,2.99,117,26.99,G,Commentaries,Behind the Scenes,2006-02-15 05:03:42\n",
      "Reçu: 5,AFRICAN EGG,A Fast-Paced Documentary of a Pastry Chef And a Dentist who must Pursue a Forensic Psychologist in The Gulf of Mexico,2006,1,,6,2.99,130,22.99,G,Deleted Scenes,2006-02-15 05:03:42\n",
      "Reçu: 6,AGENT TRUMAN,A Intrepid Panorama of a Robot And a Boy who must Escape a Sumo Wrestler in Ancient China,2006,1,,3,2.99,169,17.99,PG,Deleted Scenes,2006-02-15 05:03:42\n",
      "Reçu: 7,AIRPLANE SIERRA,A Touching Saga of a Hunter And a Butler who must Discover a Butler in A Jet Boat,2006,1,,6,4.99,62,28.99,PG-13,Trailers,Deleted Scenes,2006-02-15 05:03:42\n",
      "Reçu: 8,AIRPORT POLLOCK,An Epic Tale of a Moose And a Girl who must Confront a Monkey in Ancient India,2006,1,,6,4.99,54,15.99,R,Trailers,2006-02-15 05:03:42\n",
      "Reçu: 9,ALABAMA DEVIL,A Thoughtful Panorama of a Database Administrator And a Mad Scientist who must Outgun a Mad Scientist in A Jet Boat,2006,1,,3,2.99,114,21.99,PG-13,Trailers,Deleted Scenes,2006-02-15 05:03:42\n",
      "Reçu: 10,ALADDIN CALENDAR,A Action-Packed Tale of a Man And a Lumberjack who must Reach a Feminist in Ancient China,2006,1,,6,4.99,63,24.99,NC-17,Trailers,Deleted Scenes,2006-02-15 05:03:42\n",
      "Reçu: 11,ALAMO VIDEOTAPE,A Boring Epistle of a Butler And a Cat who must Fight a Pastry Chef in A MySQL Convention,2006,1,,6,0.99,126,16.99,G,Commentaries,Behind the Scenes,2006-02-15 05:03:42\n",
      "Reçu: 12,ALASKA PHANTOM,A Fanciful Saga of a Hunter And a Pastry Chef who must Vanquish a Boy in Australia,2006,1,,6,0.99,136,22.99,PG,Commentaries,Deleted Scenes,2006-02-15 05:03:42\n",
      "Reçu: 13,ALI FOREVER,A Action-Packed Drama of a Dentist And a Crocodile who must Battle a Feminist in The Canadian Rockies,2006,1,,4,4.99,150,21.99,PG,Deleted Scenes,Behind the Scenes,2006-02-15 05:03:42\n",
      "Reçu: 14,ALICE FANTASIA,A Emotional Drama of a A Shark And a Database Administrator who must Vanquish a Pioneer in Soviet Georgia,2006,1,,6,0.99,94,23.99,NC-17,Trailers,Deleted Scenes,Behind the Scenes,2006-02-15 05:03:42\n",
      "Reçu: 15,ALIEN CENTER,A Brilliant Drama of a Cat And a Mad Scientist who must Battle a Feminist in A MySQL Convention,2006,1,,5,2.99,46,10.99,NC-17,Trailers,Commentaries,Behind the Scenes,2006-02-15 05:03:42\n",
      "Reçu: 16,ALLEY EVOLUTION,A Fast-Paced Drama of a Robot And a Composer who must Battle a Astronaut in New Orleans,2006,1,,6,2.99,180,23.99,NC-17,Trailers,Commentaries,2006-02-15 05:03:42\n",
      "Reçu: 17,ALONE TRIP,A Fast-Paced Character Study of a Composer And a Dog who must Outgun a Boat in An Abandoned Fun House,2006,1,,3,0.99,82,14.99,R,Trailers,Behind the Scenes,2006-02-15 05:03:42\n",
      "Reçu: 18,ALTER VICTORY,A Thoughtful Drama of a Composer And a Feminist who must Meet a Secret Agent in The Canadian Rockies,2006,1,,6,0.99,57,27.99,PG-13,Trailers,Behind the Scenes,2006-02-15 05:03:42\n",
      "Reçu: 19,AMADEUS HOLY,A Emotional Display of a Pioneer And a Technical Writer who must Battle a Man in A Baloon,2006,1,,6,0.99,113,20.99,PG,Commentaries,Deleted Scenes,Behind the Scenes,2006-02-15 05:03:42\n",
      "Reçu: 20,AMELIE HELLFIGHTERS,A Boring Drama of a Woman And a Squirrel who must Conquer a Student in A Baloon,2006,1,,4,4.99,79,23.99,R,Commentaries,Deleted Scenes,Behind the Scenes,2006-02-15 05:03:42\n",
      "Reçu: 21,AMERICAN CIRCUS,A Insightful Drama of a Girl And a Astronaut who must Face a Database Administrator in A Shark Tank,2006,1,,3,4.99,129,17.99,R,Commentaries,Behind the Scenes,2006-02-15 05:03:42\n",
      "Reçu: 22,AMISTAD MIDSUMMER,A Emotional Character Study of a Dentist And a Crocodile who must Meet a Sumo Wrestler in California,2006,1,,6,2.99,85,10.99,G,Commentaries,Behind the Scenes,2006-02-15 05:03:42\n",
      "Reçu: 23,ANACONDA CONFESSIONS,A Lacklusture Display of a Dentist And a Dentist who must Fight a Girl in Australia,2006,1,,3,0.99,92,9.99,R,Trailers,Deleted Scenes,2006-02-15 05:03:42\n",
      "Reçu: 24,ANALYZE HOOSIERS,A Thoughtful Display of a Explorer And a Pastry Chef who must Overcome a Feminist in The Sahara Desert,2006,1,,6,2.99,181,19.99,R,Trailers,Behind the Scenes,2006-02-15 05:03:42\n",
      "Reçu: 25,ANGELS LIFE,A Thoughtful Display of a Woman And a Astronaut who must Battle a Robot in Berlin,2006,1,,3,2.99,74,15.99,G,Trailers,2006-02-15 05:03:42\n"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaConsumer\n",
    "\n",
    "consumer = KafkaConsumer(\n",
    "    topic2,\n",
    "    bootstrap_servers=[kafka_url],\n",
    "    auto_offset_reset='earliest',\n",
    "    consumer_timeout_ms=1000,\n",
    "    value_deserializer=lambda value: value.decode('utf-8'),\n",
    ")\n",
    "\n",
    "print(\"Liste des messages reçus:\")\n",
    "for message in consumer:\n",
    "    print(f'Reçu: {message.value}')\n",
    "\n",
    "consumer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6eda6c",
   "metadata": {},
   "source": [
    "## Administration de Kafka depuis python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b240f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka.admin import KafkaAdminClient, NewTopic\n",
    "\n",
    "admin_client = KafkaAdminClient(\n",
    "    bootstrap_servers=kafka_url,\n",
    "    client_id='test_admin'\n",
    ")\n",
    "\n",
    "topics = admin_client.list_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116758da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_topic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m new_topic_name= \u001b[33m'\u001b[39m\u001b[33mtopic-from-python\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnew_topic\u001b[49m-Name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m topics:\n\u001b[32m      3\u001b[39m     topic = NewTopic(name=new_topic_name, num_partitions=\u001b[32m1\u001b[39m, replication_factor=\u001b[32m1\u001b[39m)\n\u001b[32m      4\u001b[39m     admin_client.create_topics(new_topics=[topic], validate_only=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'new_topic' is not defined"
     ]
    }
   ],
   "source": [
    "new_topic_name= 'topic-from-python'\n",
    "if new_topic_name not in topics:\n",
    "    topic = NewTopic(name=new_topic_name, num_partitions=1, replication_factor=1)\n",
    "    admin_client.create_topics(new_topics=[topic], validate_only=False)\n",
    "    print(f'Topic\"{new_topic_name}\" existe déjà.')\n",
    "else:\n",
    "    print(f'Topic\"{new_topic_name}\"existe déjà.')\n",
    "    \n",
    "# Supprinmer le topic\n",
    "\n",
    "admin_client.delete_topics([new_topic_name]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24986029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteTopicsResponse_v3(throttle_time_ms=0, topic_error_codes=[(topic='topic-example', error_code=0)])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_topic_name= 'topic-example'\n",
    "admin_client.delete_topics([new_topic_name]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6db66458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration de rétention du topic\"topic-example\" modifiée pour supprimer les messages immédiatement.\n",
      "Configuration de rétention du topic \"topic-example\"remise à 7 jours\n"
     ]
    }
   ],
   "source": [
    "from kafka.admin import ConfigResource, ConfigResourceType\n",
    "\n",
    "resource = ConfigResource(\n",
    "    ConfigResourceType.TOPIC,\n",
    "    topic, \n",
    "    configs={\"retention.ms\": \"0\"} # 0 milli-secondes\n",
    "    \n",
    ")\n",
    "\n",
    "admin_client.alter_configs([ressource])\n",
    "print(f'Configuration de rétention du topic\"{topic2}\" modifiée pour supprimer les messages immédiatement.')\n",
    "\n",
    "# Remettre la configuration par défaut (7 jours)\n",
    "resource = ConfigResource(\n",
    "    ConfigResourceType.TOPIC,\n",
    "    topics,\n",
    "    configs={ \"retention.ms\": str(7 * 24 * 60 * 60 * 1000)} # 7 jours\n",
    ")\n",
    "\n",
    "admin_client.alter_configs([resource])\n",
    "print(f'Configuration de rétention du topic \"{topic2}\"remise à 7 jours')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Spark)",
   "language": "python",
   "name": "spark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
