{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "343d6851",
   "metadata": {},
   "source": [
    "# Producer Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e85482df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from kafka import KafkaProducer\n",
    "import csv\n",
    "\n",
    "kafka_url = 'kafka:9092'\n",
    "\n",
    "#Démarrer le producteur Kafka\n",
    "producer = KafkaProducer(bootstrap_servers=kafka_url, value_serializer=lambda v: str(v).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da4f7c0",
   "metadata": {},
   "source": [
    "## Envoi de message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d737654a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'producer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m):\n\u001b[32m      4\u001b[39m     message = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mMessage \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43mproducer\u001b[49m.send(topic, value=message)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEnvoyé:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m     time.sleep(\u001b[32m1\u001b[39m) \u001b[38;5;66;03m# Pause pour simuler un flux\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'producer' is not defined"
     ]
    }
   ],
   "source": [
    "topic = 'topic-example'\n",
    "\n",
    "for i in range(10):\n",
    "    message = f'Message {i}'\n",
    "    producer.send(topic, value=message)\n",
    "    print(f'Envoyé:{message}')\n",
    "    time.sleep(1) # Pause pour simuler un flux\n",
    "    \n",
    "producer.flush()\n",
    "producer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1733f7",
   "metadata": {},
   "source": [
    "## Consumer Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83bea950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liste des messages reçus:\n",
      "Reçu: Message 0\n",
      "Reçu: Message 1\n",
      "Reçu: Message 2\n",
      "Reçu: Message 3\n",
      "Reçu: Message 4\n",
      "Reçu: Message 5\n",
      "Reçu: Message 6\n",
      "Reçu: Message 7\n",
      "Reçu: Message 8\n",
      "Reçu: Message 9\n"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaConsumer\n",
    "\n",
    "consumer = KafkaConsumer(\n",
    "    topic,\n",
    "    bootstrap_servers=[kafka_url],\n",
    "    auto_offset_reset ='earliest',\n",
    "    consumer_timeout_ms=1000,\n",
    "    value_deserializer=lambda value: value.decode('utf-8'),\n",
    "    \n",
    ")\n",
    "\n",
    "print(\"Liste des messages reçus:\")\n",
    "for message in consumer:\n",
    "    print(f'Reçu: {message.value}')\n",
    "    \n",
    "consumer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75268f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read the CSV file\n",
    "with open('data/test.csv', mode='r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    header = next(reader)  # skip header if needed\n",
    "\n",
    "    for row in reader:\n",
    "        message = ','.join(row)  # convert row to string\n",
    "        producer.send(topic, value=message)\n",
    "        print(f'Envoyé: {message}')\n",
    "        time.sleep(1)  # simulate streaming\n",
    "\n",
    "producer.flush()\n",
    "producer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05779d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_url = 'kafka:9092'\n",
    "\n",
    "# Démarrer le producteur Kafka\n",
    "producer = KafkaProducer(bootstrap_servers=kafka_url, value_serializer=lambda v: str(v).encode('utf-8'))\n",
    "topic2 = 'topic-example-file'\n",
    "\n",
    "# Open and read the CSV file\n",
    "with open('data/film.csv','r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    header = next(reader)  # skip header if needed\n",
    "\n",
    "    for i, row in enumerate(reader):\n",
    "        if i >= 100:  # limit to first 100 rows\n",
    "            break\n",
    "        message = ','.join(row)  # convert row to string\n",
    "        producer.send(topic2, value=message)\n",
    "        print(f'Envoyé: {message}')\n",
    "        time.sleep(1)  # simulate streaming\n",
    "\n",
    "producer.flush()\n",
    "producer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa207232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "\n",
    "consumer = KafkaConsumer(\n",
    "    topic2,\n",
    "    bootstrap_servers=[kafka_url],\n",
    "    auto_offset_reset='earliest',\n",
    "    consumer_timeout_ms=1000,\n",
    "    value_deserializer=lambda value: value.decode('utf-8'),\n",
    ")\n",
    "\n",
    "print(\"Liste des messages reçus:\")\n",
    "for message in consumer:\n",
    "    print(f'Reçu: {message.value}')\n",
    "\n",
    "consumer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6eda6c",
   "metadata": {},
   "source": [
    "## Administration de Kafka depuis python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b240f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka.admin import KafkaAdminClient, NewTopic\n",
    "\n",
    "admin_client = KafkaAdminClient(\n",
    "    bootstrap_servers=kafka_url,\n",
    "    client_id='test_admin'\n",
    ")\n",
    "\n",
    "topics = admin_client.list_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116758da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_topic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m new_topic_name= \u001b[33m'\u001b[39m\u001b[33mtopic-from-python\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnew_topic\u001b[49m-Name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m topics:\n\u001b[32m      3\u001b[39m     topic = NewTopic(name=new_topic_name, num_partitions=\u001b[32m1\u001b[39m, replication_factor=\u001b[32m1\u001b[39m)\n\u001b[32m      4\u001b[39m     admin_client.create_topics(new_topics=[topic], validate_only=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'new_topic' is not defined"
     ]
    }
   ],
   "source": [
    "new_topic_name= 'topic-from-python'\n",
    "if new_topic_name not in topics:\n",
    "    topic = NewTopic(name=new_topic_name, num_partitions=1, replication_factor=1)\n",
    "    admin_client.create_topics(new_topics=[topic], validate_only=False)\n",
    "    print(f'Topic\"{new_topic_name}\" existe déjà.')\n",
    "else:\n",
    "    print(f'Topic\"{new_topic_name}\"existe déjà.')\n",
    "    \n",
    "# Supprinmer le topic\n",
    "\n",
    "admin_client.delete_topics([new_topic_name]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24986029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteTopicsResponse_v3(throttle_time_ms=0, topic_error_codes=[(topic='topic-example', error_code=0)])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_topic_name= 'topic-example'\n",
    "admin_client.delete_topics([new_topic_name]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af21f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_server = \"localhost:9092\"  # or your actual broker address\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6db66458",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkafka\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01madmin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConfigResource, ConfigResourceType\n\u001b[32m      3\u001b[39m resource = ConfigResource(\n\u001b[32m      4\u001b[39m     ConfigResourceType.TOPIC,\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43mtopic\u001b[49m, \n\u001b[32m      6\u001b[39m     configs={\u001b[33m\"\u001b[39m\u001b[33mretention.ms\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m} \u001b[38;5;66;03m# 0 milli-secondes\u001b[39;00m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m admin_client.alter_configs([ressource])\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mConfiguration de rétention du topic\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopic2\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m modifiée pour supprimer les messages immédiatement.\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'topic' is not defined"
     ]
    }
   ],
   "source": [
    "from kafka.admin import ConfigResource, ConfigResourceType\n",
    "\n",
    "resource = ConfigResource(\n",
    "    ConfigResourceType.TOPIC,\n",
    "    topic, \n",
    "    configs={\"retention.ms\": \"0\"} # 0 milli-secondes\n",
    "    \n",
    ")\n",
    "\n",
    "admin_client.alter_configs([ressource])\n",
    "print(f'Configuration de rétention du topic\"{topic2}\" modifiée pour supprimer les messages immédiatement.')\n",
    "\n",
    "# Remettre la configuration par défaut (7 jours)\n",
    "resource = ConfigResource(\n",
    "    ConfigResourceType.TOPIC,\n",
    "    topics,\n",
    "    configs={ \"retention.ms\": str(7 * 24 * 60 * 60 * 1000)} # 7 jours\n",
    ")\n",
    "\n",
    "admin_client.alter_configs([resource])\n",
    "print(f'Configuration de rétention du topic \"{topic2}\"remise à 7 jours')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Spark)",
   "language": "python",
   "name": "spark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
